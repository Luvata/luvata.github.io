{"Graph":{"adjacencyMap":{"@baoUniLMv2PseudoMaskedLanguage2020":{},"@yangXLNetGeneralizedAutoregressive2020":{},"@lampleCrosslingualLanguageModel2019":{},"@daiTransformerXLAttentiveLanguage2019":{},"@khandelwalGENERALIZATIONMEMORIZATIONNEAREST2020":{},"@liuRoBERTaRobustlyOptimized2019":{},"@zhangUnderstandingDeepLearning2017":{},"README":{"papers":["cf",[]]},"@radfordLanguageModelsAre":{"@carliniExtractingTrainingData2020":["cf",[]]},"@keskarCTRLConditionalTransformer2019":{},"@wenzekCCNetExtractingHigh2019":{},"@radfordImprovingLanguageUnderstanding":{},"@dewynterOptimalSubarchitectureExtraction2020":{},"@carliniExtractingTrainingData2020":{},"@holtzmanCuriousCaseNeural2020a":{},"@lewisBARTDenoisingSequencetoSequence2019":{},"@joshiSpanBERTImprovingPretraining2020":{"@lewisBARTDenoisingSequencetoSequence2019":["cf",[]]},"@clarkELECTRAPretrainingText2020":{},"papers":{"@baoUniLMv2PseudoMaskedLanguage2020":["cf",[]],"@yangXLNetGeneralizedAutoregressive2020":["cf",[]],"@lampleCrosslingualLanguageModel2019":["cf",[]],"@daiTransformerXLAttentiveLanguage2019":["cf",[]],"@khandelwalGENERALIZATIONMEMORIZATIONNEAREST2020":["cf",[]],"@liuRoBERTaRobustlyOptimized2019":["cf",[]],"@zhangUnderstandingDeepLearning2017":["cf",[]],"@radfordLanguageModelsAre":["cf",[]],"@keskarCTRLConditionalTransformer2019":["cf",[]],"@wenzekCCNetExtractingHigh2019":["cf",[]],"@radfordImprovingLanguageUnderstanding":["cf",[]],"@dewynterOptimalSubarchitectureExtraction2020":["cf",[]],"@carliniExtractingTrainingData2020":["cf",[]],"@holtzmanCuriousCaseNeural2020a":["cf",[]],"@lewisBARTDenoisingSequencetoSequence2019":["cf",[]],"@joshiSpanBERTImprovingPretraining2020":["cf",[]],"@clarkELECTRAPretrainingText2020":["cf",[]],"@assenmacherComparabilityPretrainedLanguage2020":["cf",[]],"@dongUnifiedLanguageModel2019":["cf",[]]},"@koltunMeasureResearchTaste2021":{},"index":{"README":["folge",[]]},"@assenmacherComparabilityPretrainedLanguage2020":{},"@dongUnifiedLanguageModel2019":{}},"vertices":{"@baoUniLMv2PseudoMaskedLanguage2020":{"Path":"./static/@baoUniLMv2PseudoMaskedLanguage2020.md","Slug":"@baoUniLMv2PseudoMaskedLanguage2020","ID":"@baoUniLMv2PseudoMaskedLanguage2020","Meta":{"authors":"Hangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan Yang, Xiaodong Liu, Yu Wang, Songhao Piao, Jianfeng Gao, Ming Zhou, Hsiao-Wuen Hon","citekey":"baoUniLMv2PseudoMaskedLanguage2020","year":2020,"title":"UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training","tags":[]},"Title":"UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training"},"@yangXLNetGeneralizedAutoregressive2020":{"Path":"./static/@yangXLNetGeneralizedAutoregressive2020.md","Slug":"@yangXLNetGeneralizedAutoregressive2020","ID":"@yangXLNetGeneralizedAutoregressive2020","Meta":{"authors":"Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le","citekey":"yangXLNetGeneralizedAutoregressive2020","year":2020,"title":"XLNet: Generalized Autoregressive Pretraining for Language Understanding","tags":[]},"Title":"XLNet: Generalized Autoregressive Pretraining for Language Understanding"},"@lampleCrosslingualLanguageModel2019":{"Path":"./static/@lampleCrosslingualLanguageModel2019.md","Slug":"@lampleCrosslingualLanguageModel2019","ID":"@lampleCrosslingualLanguageModel2019","Meta":{"authors":"Guillaume Lample, Alexis Conneau","citekey":"lampleCrosslingualLanguageModel2019","year":2019,"title":"Cross-lingual Language Model Pretraining","tags":[]},"Title":"Cross-lingual Language Model Pretraining"},"@daiTransformerXLAttentiveLanguage2019":{"Path":"./static/@daiTransformerXLAttentiveLanguage2019.md","Slug":"@daiTransformerXLAttentiveLanguage2019","ID":"@daiTransformerXLAttentiveLanguage2019","Meta":{"authors":"Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov","citekey":"daiTransformerXLAttentiveLanguage2019","year":2019,"title":"Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context","tags":["RECL"]},"Title":"Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"},"@khandelwalGENERALIZATIONMEMORIZATIONNEAREST2020":{"Path":"./static/@khandelwalGENERALIZATIONMEMORIZATIONNEAREST2020.md","Slug":"@khandelwalGENERALIZATIONMEMORIZATIONNEAREST2020","ID":"@khandelwalGENERALIZATIONMEMORIZATIONNEAREST2020","Meta":{"authors":"Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, Mike Lewis","citekey":"khandelwalGENERALIZATIONMEMORIZATIONNEAREST2020","year":2019,"title":"GENERALIZATION THROUGH MEMORIZATION: NEAREST NEIGHBOR LANGUAGE MODELS","tags":[]},"Title":"GENERALIZATION THROUGH MEMORIZATION: NEAREST NEIGHBOR LANGUAGE MODELS"},"@liuRoBERTaRobustlyOptimized2019":{"Path":"./static/@liuRoBERTaRobustlyOptimized2019.md","Slug":"@liuRoBERTaRobustlyOptimized2019","ID":"@liuRoBERTaRobustlyOptimized2019","Meta":{"authors":"Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov","citekey":"liuRoBERTaRobustlyOptimized2019","year":2019,"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach","tags":[]},"Title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach"},"@zhangUnderstandingDeepLearning2017":{"Path":"./static/@zhangUnderstandingDeepLearning2017.md","Slug":"@zhangUnderstandingDeepLearning2017","ID":"@zhangUnderstandingDeepLearning2017","Meta":{"authors":"Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals","citekey":"zhangUnderstandingDeepLearning2017","year":2017,"title":"Understanding deep learning requires rethinking generalization","tags":[]},"Title":"Understanding deep learning requires rethinking generalization"},"README":{"Path":"./README.md","Slug":"README","ID":"README","Meta":{"tags":[]},"Title":"Thanh’s index"},"@radfordLanguageModelsAre":{"Path":"./static/@radfordLanguageModelsAre.md","Slug":"@radfordLanguageModelsAre","ID":"@radfordLanguageModelsAre","Meta":{"authors":"Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever","citekey":"radfordLanguageModelsAre","year":null,"title":"Language Models are Unsupervised Multitask Learners","tags":[]},"Title":"Language Models are Unsupervised Multitask Learners"},"@keskarCTRLConditionalTransformer2019":{"Path":"./static/@keskarCTRLConditionalTransformer2019.md","Slug":"@keskarCTRLConditionalTransformer2019","ID":"@keskarCTRLConditionalTransformer2019","Meta":{"authors":"Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, Richard Socher","citekey":"keskarCTRLConditionalTransformer2019","year":2019,"title":"CTRL: A Conditional Transformer Language Model for Controllable Generation","tags":[]},"Title":"CTRL: A Conditional Transformer Language Model for Controllable Generation"},"@wenzekCCNetExtractingHigh2019":{"Path":"./static/@wenzekCCNetExtractingHigh2019.md","Slug":"@wenzekCCNetExtractingHigh2019","ID":"@wenzekCCNetExtractingHigh2019","Meta":{"authors":"Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzmán, Armand Joulin, Edouard Grave","citekey":"wenzekCCNetExtractingHigh2019","year":2019,"title":"CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data","tags":[]},"Title":"CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data"},"@radfordImprovingLanguageUnderstanding":{"Path":"./static/@radfordImprovingLanguageUnderstanding.md","Slug":"@radfordImprovingLanguageUnderstanding","ID":"@radfordImprovingLanguageUnderstanding","Meta":{"authors":"Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever","citekey":"radfordImprovingLanguageUnderstanding","year":null,"title":"Improving Language Understanding by Generative Pre-Training","tags":[]},"Title":"Improving Language Understanding by Generative Pre-Training"},"@dewynterOptimalSubarchitectureExtraction2020":{"Path":"./static/@dewynterOptimalSubarchitectureExtraction2020.md","Slug":"@dewynterOptimalSubarchitectureExtraction2020","ID":"@dewynterOptimalSubarchitectureExtraction2020","Meta":{"authors":"Adrian Wynter, Daniel J. Perry","citekey":"dewynterOptimalSubarchitectureExtraction2020","year":2020,"title":"Optimal Subarchitecture Extraction For BERT","tags":["ABnC-property","FPTAS-solver","L-Lipschitz-smoothness"]},"Title":"Optimal Subarchitecture Extraction For BERT"},"@carliniExtractingTrainingData2020":{"Path":"./static/@carliniExtractingTrainingData2020.md","Slug":"@carliniExtractingTrainingData2020","ID":"@carliniExtractingTrainingData2020","Meta":{"authors":"Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, Alina Oprea, Colin Raffel","citekey":"carliniExtractingTrainingData2020","year":2020,"title":"Extracting Training Data from Large Language Models","tags":[]},"Title":"Extracting Training Data from Large Language Models"},"@holtzmanCuriousCaseNeural2020a":{"Path":"./static/@holtzmanCuriousCaseNeural2020a.md","Slug":"@holtzmanCuriousCaseNeural2020a","ID":"@holtzmanCuriousCaseNeural2020a","Meta":{"authors":"Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi","citekey":"holtzmanCuriousCaseNeural2020a","year":2020,"title":"The Curious Case of Neural Text Degeneration","tags":[]},"Title":"The Curious Case of Neural Text Degeneration"},"@lewisBARTDenoisingSequencetoSequence2019":{"Path":"./static/@lewisBARTDenoisingSequencetoSequence2019.md","Slug":"@lewisBARTDenoisingSequencetoSequence2019","ID":"@lewisBARTDenoisingSequencetoSequence2019","Meta":{"authors":"Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, Luke Zettlemoyer","citekey":"lewisBARTDenoisingSequencetoSequence2019","year":2019,"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension","tags":[]},"Title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},"@joshiSpanBERTImprovingPretraining2020":{"Path":"./static/@joshiSpanBERTImprovingPretraining2020.md","Slug":"@joshiSpanBERTImprovingPretraining2020","ID":"@joshiSpanBERTImprovingPretraining2020","Meta":{"authors":"Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, Omer Levy","citekey":"joshiSpanBERTImprovingPretraining2020","year":2020,"title":"SpanBERT: Improving Pre-training by Representing and Predicting Spans","tags":[]},"Title":"SpanBERT: Improving Pre-training by Representing and Predicting Spans"},"@clarkELECTRAPretrainingText2020":{"Path":"./static/@clarkELECTRAPretrainingText2020.md","Slug":"@clarkELECTRAPretrainingText2020","ID":"@clarkELECTRAPretrainingText2020","Meta":{"authors":"Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning","citekey":"clarkELECTRAPretrainingText2020","year":2020,"title":"ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators","tags":[]},"Title":"ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators"},"papers":{"Path":"./papers.md","Slug":"papers","ID":"papers","Meta":{"tags":[]},"Title":"Paper reading"},"@koltunMeasureResearchTaste2021":{"Path":"./static/@koltunMeasureResearchTaste2021.md","Slug":"@koltunMeasureResearchTaste2021","ID":"@koltunMeasureResearchTaste2021","Meta":{"authors":"Vladlen Koltun, David Hafner","citekey":"koltunMeasureResearchTaste2021","year":2021,"title":"A Measure of Research Taste","tags":[]},"Title":"A Measure of Research Taste"},"index":{"Path":"./index.md","Slug":"index","ID":"index","Meta":{"tags":[]},"Title":"Thanh’s Blog"},"@assenmacherComparabilityPretrainedLanguage2020":{"Path":"./static/@assenmacherComparabilityPretrainedLanguage2020.md","Slug":"@assenmacherComparabilityPretrainedLanguage2020","ID":"@assenmacherComparabilityPretrainedLanguage2020","Meta":{"authors":"Matthias Aßenmacher, Christian Heumann","citekey":"assenmacherComparabilityPretrainedLanguage2020","year":2020,"title":"On the comparability of Pre-trained Language Models","tags":[]},"Title":"On the comparability of Pre-trained Language Models"},"@dongUnifiedLanguageModel2019":{"Path":"./static/@dongUnifiedLanguageModel2019.md","Slug":"@dongUnifiedLanguageModel2019","ID":"@dongUnifiedLanguageModel2019","Meta":{"authors":"Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, Hsiao-Wuen Hon","citekey":"dongUnifiedLanguageModel2019","year":2019,"title":"Unified Language Model Pre-training for Natural Language Understanding and Generation","tags":[]},"Title":"Unified Language Model Pre-training for Natural Language Understanding and Generation"}}},"NeuronVersion":"1.9.31.0","Config":{"editUrl":"https://github.com/luvata/blogs/edit/master/","plugins":["neuronignore","links","tags","uptree","feed"],"siteBaseUrl":"https://luvata.github.io/blogs/","author":"Thanh Le","siteTitle":"Luvata's blog","theme":"brown"},"Errors":{"@baoUniLMv2PseudoMaskedLanguage2020":{"tag":"ZettelIssue_MissingLinks","contents":["@baoUniLMv2PseudoMaskedLanguage2020",["Screen Shot 2021-05-12 at 11.03.52.png","Screen Shot 2021-05-12 at 11.17.59.png","Screen Shot 2021-05-12 at 11.39.18.png","Screen Shot 2021-05-12 at 11.39.28.png","Screen Shot 2021-05-12 at 13.29.58.png","Screen Shot 2021-05-12 at 13.30.22.png","Screen Shot 2021-05-12 at 13.30.40.png"]]},"@yangXLNetGeneralizedAutoregressive2020":{"tag":"ZettelIssue_MissingLinks","contents":["@yangXLNetGeneralizedAutoregressive2020",["Screen Shot 2021-05-15 at 10.50.12.png","Screen Shot 2021-05-15 at 10.51.53.png","Screen Shot 2021-05-15 at 11.05.40.png","Screen Shot 2021-05-15 at 11.09.26.png","Screen Shot 2021-05-15 at 11.09.43.png","Screen Shot 2021-05-15 at 11.10.43.png","Screen Shot 2021-05-15 at 11.17.29.png"]]},"@lampleCrosslingualLanguageModel2019":{"tag":"ZettelIssue_MissingLinks","contents":["@lampleCrosslingualLanguageModel2019",["Screen Shot 2021-05-12 at 16.03.18.png"]]},"@daiTransformerXLAttentiveLanguage2019":{"tag":"ZettelIssue_MissingLinks","contents":["@daiTransformerXLAttentiveLanguage2019",["Screen Shot 2021-05-13 at 15.35.06.png","Screen Shot 2021-05-14 at 23.10.28.png","Screen Shot 2021-05-14 at 23.24.44.png","Screen Shot 2021-05-14 at 23.26.01.png","Screen Shot 2021-05-14 at 23.44.46.png","Screen Shot 2021-05-14 at 23.46.45.png","Screen Shot 2021-05-14 at 23.48.17.png"]]},"@khandelwalGENERALIZATIONMEMORIZATIONNEAREST2020":{"tag":"ZettelIssue_MissingLinks","contents":["@khandelwalGENERALIZATIONMEMORIZATIONNEAREST2020",["Screen Shot 2021-05-04 at 09.07.29.png"]]},"@liuRoBERTaRobustlyOptimized2019":{"tag":"ZettelIssue_MissingLinks","contents":["@liuRoBERTaRobustlyOptimized2019",["Screen Shot 2021-05-12 at 14.57.47.png"]]},"@zhangUnderstandingDeepLearning2017":{"tag":"ZettelIssue_MissingLinks","contents":["@zhangUnderstandingDeepLearning2017",["Screen Shot 2021-05-08 at 23.47.17.png","Screen Shot 2021-05-08 at 23.55.04.png","Screen Shot 2021-05-09 at 00.07.20.png"]]},"@radfordLanguageModelsAre":{"tag":"ZettelIssue_MissingLinks","contents":["@radfordLanguageModelsAre",["Screen Shot 2021-05-02 at 21.03.07.png","Screen Shot 2021-05-02 at 21.16.14.png"]]},"@keskarCTRLConditionalTransformer2019":{"tag":"ZettelIssue_MissingLinks","contents":["@keskarCTRLConditionalTransformer2019",["Screen Shot 2021-05-18 at 19.30.17.png"]]},"@wenzekCCNetExtractingHigh2019":{"tag":"ZettelIssue_MissingLinks","contents":["@wenzekCCNetExtractingHigh2019",["Screen Shot 2021-05-07 at 16.29.42.png","Screen Shot 2021-05-07 at 16.36.25.png","Screen Shot 2021-05-07 at 16.38.40.png"]]},"@radfordImprovingLanguageUnderstanding":{"tag":"ZettelIssue_MissingLinks","contents":["@radfordImprovingLanguageUnderstanding",["Screen Shot 2021-05-01 at 19.33.20.png","Screen Shot 2021-05-01 at 19.44.31.png"]]},"@dewynterOptimalSubarchitectureExtraction2020":{"tag":"ZettelIssue_MissingLinks","contents":["@dewynterOptimalSubarchitectureExtraction2020",["Screen Shot 2021-05-13 at 14.16.35.png"]]},"@carliniExtractingTrainingData2020":{"tag":"ZettelIssue_MissingLinks","contents":["@carliniExtractingTrainingData2020",["Screen Shot 2021-05-03 at 16.01.54.png","Screen Shot 2021-05-03 at 16.06.33.png","Screen Shot 2021-05-03 at 16.12.25.png"]]},"@holtzmanCuriousCaseNeural2020a":{"tag":"ZettelIssue_MissingLinks","contents":["@holtzmanCuriousCaseNeural2020a",["Screen Shot 2021-05-11 at 00.38.25.png","Screen Shot 2021-05-11 at 00.54.27.png"]]},"@lewisBARTDenoisingSequencetoSequence2019":{"tag":"ZettelIssue_MissingLinks","contents":["@lewisBARTDenoisingSequencetoSequence2019",["Screen Shot 2021-05-12 at 15.09.56.png","Screen Shot 2021-05-12 at 15.14.13.png","Screen Shot 2021-05-12 at 15.22.56.png"]]},"@joshiSpanBERTImprovingPretraining2020":{"tag":"ZettelIssue_MissingLinks","contents":["@joshiSpanBERTImprovingPretraining2020",["Screen Shot 2021-05-13 at 14.52.33.png","Screen Shot 2021-05-13 at 14.54.01.png","Screen Shot 2021-05-13 at 14.57.24.png","Screen Shot 2021-05-13 at 15.04.20.png"]]},"@clarkELECTRAPretrainingText2020":{"tag":"ZettelIssue_MissingLinks","contents":["@clarkELECTRAPretrainingText2020",["Screen Shot 2021-05-15 at 12.18.07.png","Screen Shot 2021-05-15 at 12.30.02.png","Screen Shot 2021-05-15 at 12.36.13.png"]]},"@assenmacherComparabilityPretrainedLanguage2020":{"tag":"ZettelIssue_MissingLinks","contents":["@assenmacherComparabilityPretrainedLanguage2020",["Screen Shot 2021-05-06 at 16.46.41.png","Screen Shot 2021-05-06 at 16.47.09.png"]]},"@dongUnifiedLanguageModel2019":{"tag":"ZettelIssue_MissingLinks","contents":["@dongUnifiedLanguageModel2019",["Screen Shot 2021-05-11 at 23.40.52.png","Screen Shot 2021-05-11 at 23.44.00.png"]]}}}